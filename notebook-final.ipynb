{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":104491,"databundleVersionId":12585144,"sourceType":"competition"},{"sourceId":12137862,"sourceType":"datasetVersion","datasetId":7643960}],"dockerImageVersionId":31040,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# üì¶ Import required libraries\nimport pandas as pd\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# üìÇ Load datasets\ntrain_df = pd.read_csv(\"/kaggle/input/summer-analytics-mid-hackathon/hacktrain.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/summer-analytics-mid-hackathon/hacktest.csv\")\n\n# üßπ Drop unnecessary column\ntrain_df.drop(columns=['Unnamed: 0'], inplace=True)\ntest_df.drop(columns=['Unnamed: 0'], inplace=True)\n\n# üè∑Ô∏è Separate target and features\nX_raw = train_df.drop(columns=['class', 'ID'])\ny = train_df['class']\ntest_raw = test_df.drop(columns=['ID'])\n\ntrain_ids = train_df['ID']\ntest_ids = test_df['ID']\n\n# üßº Handle missing values by imputing column mean\nimputer = SimpleImputer(strategy='mean')\nX_imputed = pd.DataFrame(imputer.fit_transform(X_raw), columns=X_raw.columns)\ntest_imputed = pd.DataFrame(imputer.transform(test_raw), columns=test_raw.columns)\n\n# üß† Feature engineering function\ndef extract_features(df):\n    return pd.DataFrame({\n        'ndvi_mean': df.mean(axis=1),\n        'ndvi_std': df.std(axis=1),\n        'ndvi_min': df.min(axis=1),\n        'ndvi_max': df.max(axis=1),\n        'ndvi_median': df.median(axis=1),\n        'ndvi_range': df.max(axis=1) - df.min(axis=1),\n        'ndvi_first': df.iloc[:, 0],\n        'ndvi_last': df.iloc[:, -1],\n        'ndvi_trend': df.iloc[:, -1] - df.iloc[:, 0],\n    })\n\n# üß™ Extract features\nX_features = extract_features(X_imputed)\ntest_features = extract_features(test_imputed)\n\n# üî¢ Encode class labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# üß™ Optional: Train-validation split for local testing\nX_train, X_val, y_train, y_val = train_test_split(\n    X_features, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n)\n\n# üîÅ Train logistic regression model\nmodel = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=2000)\nmodel.fit(X_train, y_train)\n\n# üìä Evaluate model on validation set\nval_preds = model.predict(X_val)\nprint(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\nprint(\"\\nClassification Report:\\n\", classification_report(y_val, val_preds, target_names=label_encoder.classes_))\n\n# ‚úÖ Retrain on full data\nmodel_final = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=2000)\nmodel_final.fit(X_features, y_encoded)\n\n# üîÆ Predict on test set\ntest_preds = model_final.predict(test_features)\ntest_preds_labels = label_encoder.inverse_transform(test_preds)\n\n# üìÑ Create submission DataFrame\nsubmission_df = pd.DataFrame({\n    'ID': test_ids,\n    'class': test_preds_labels\n})\n\n# üíæ Save to CSV\nsubmission_df.to_csv(\"submission.csv\", index=False)\n\nprint(\"‚úÖ submission.csv generated!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T13:20:08.395867Z","iopub.execute_input":"2025-06-12T13:20:08.396157Z","iopub.status.idle":"2025-06-12T13:20:38.924928Z","shell.execute_reply.started":"2025-06-12T13:20:08.396135Z","shell.execute_reply":"2025-06-12T13:20:38.923259Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"},{"name":"stdout","text":"Validation Accuracy: 0.830625\n\nClassification Report:\n               precision    recall  f1-score   support\n\n        farm       0.48      0.12      0.20       168\n      forest       0.86      0.98      0.91      1232\n       grass       0.54      0.18      0.27        39\n  impervious       0.70      0.64      0.67       134\n     orchard       0.00      0.00      0.00         6\n       water       0.75      0.57      0.65        21\n\n    accuracy                           0.83      1600\n   macro avg       0.55      0.42      0.45      1600\nweighted avg       0.79      0.83      0.79      1600\n\n‚úÖ submission.csv generated!\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}],"execution_count":1}]}